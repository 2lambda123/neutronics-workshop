{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Techniques for sampling parameter space - Adaptive sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For adaptive sampling, the notebook needs some additional dependencies.\n",
    "\n",
    "import adaptive\n",
    "import holoviews\n",
    "import ipywidgets\n",
    "import nest_asyncio\n",
    "\n",
    "adaptive.notebook_extension()\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptive sampling is a sampling technique which uses data fitting to decide where in the parameter space to sample next. By fitting the data from samples that have already been taken, the overall data trend across the parameter space can be roughly predicted and an informed choice on where to sample the parameter space next can be made. Regions in the parameter space where the data trend is relatively flat do not have to be sampled as densely as rapidly changing regions. By allowing sample points to be chosen based on the data trend, computational time can be focused on the most important parts of the data trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code runs a neutronics simulation using a simple pre-defined model. Simulations begin by sampling the limits of the parameter space (i.e. (enrichment, breeder percentage) = (0, 100), (100, 0), (0, 100), (100, 100)) and then fitting these points to predict where TBR is varying most rapidly across the parameter space. A sample is then taken at this point and the process repeated. There are many ways to fit existing data points during adaptive sampling, however, this particular example uses gaussian process regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "from openmc_model import find_tbr_hcpb\n",
    "from plot_sampling_coordinates import plot_simulation_results, read_in_data\n",
    "from plot_interpolated_results import plot_interpolated_results\n",
    "\n",
    "\n",
    "def find_tbr(x):\n",
    "\n",
    "    breeder_percent_in_breeder_plus_multiplier_ratio, blanket_breeder_li6_enrichment = x\n",
    "                           \n",
    "    result = find_tbr_hcpb(breeder_percent_in_breeder_plus_multiplier_ratio,\n",
    "                           blanket_breeder_li6_enrichment)\n",
    "\n",
    "    result[\"sample\"] = \"adaptive\"\n",
    "\n",
    "    filename = \"outputs/\" + str(uuid.uuid4()) + \".json\"\n",
    "    Path(filename).parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(filename, mode=\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result, f, indent=4)\n",
    "\n",
    "    return result[\"tbr\"]\n",
    "\n",
    "\n",
    "number_of_simulations = 16\n",
    "\n",
    "\n",
    "print(\"running simulations with adaptive sampling\")\n",
    "\n",
    "learner = adaptive.Learner2D(find_tbr, bounds=[(0, 100), (0, 100)])\n",
    "\n",
    "runner = adaptive.Runner(learner, ntasks=1, goal=lambda l: l.npoints > number_of_simulations)\n",
    "\n",
    "# example goal setting for acceptable coverage error is also possible\n",
    "# runner = adaptive.Runner(learner, ntasks=1, goal=lambda l: l.loss() < 0.01)\n",
    "\n",
    "runner.live_info()\n",
    "# runner.live_plot()\n",
    "\n",
    "runner.ioloop.run_until_complete(runner.task)\n",
    "\n",
    "print(\"results saved in outputs folder\")\n",
    "\n",
    "results_df = read_in_data()\n",
    "filtered_results_df = results_df[results_df[\"sample\"] == \"adaptive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "\n",
    "plot_simulation_results(filtered_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot interpolated results\n",
    "\n",
    "plot_interpolated_results(filtered_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, the most important parts of a data trend are (usually) the regions where the data is changing as a function of parameter values. In our example, these are the regions where TBR is changing as a function of enrichment and breeder percentage. I.e. we do not want to excessively sample regions where TBR changes negligibly as a function of enrichment and breeder percentage. As shown, the parameter space is densely sampled in regions where TBR is changing most rapidly, and sparsely sampled in regions where TBR is changing negligibly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main advantage of adaptive sampling is that it is the most efficient technique for sampling a parameter space with an unknown distribution. By iteratively fitting the data and performing additional simulations we can determine an accurate distribution across the parameter space with fewer simulations than any other sampling technique. It is not a perfect solution, however, because over-sampling could still take place if we don't specify when to stop sampling. I.e. we would calculate the data fit and stop when we reach an acceptable uncertainty. Also could miss areas which have less prominent trends? I.e we don't get the whole picture across the whole parameter space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, adaptive sampling allows computational time to be focused on the most important parts of a distribution and is a highly efficient way of sampling a parameter space and, therefore, performing simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To more accurately cover this parameter space more than the default 40 samples would be required."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
